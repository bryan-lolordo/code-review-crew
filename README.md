# ğŸ” Code Review Crew - Multi-Agent Code Analysis System

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![AutoGen](https://img.shields.io/badge/AutoGen-0.2.32-green.svg)](https://github.com/microsoft/autogen)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

An intelligent multi-agent system powered by **Microsoft AutoGen** that performs comprehensive code reviews through collaborative AI agents. Multiple specialized agents work together, discussing and debating code quality, security vulnerabilities, and performance optimizations to provide expert-level feedback.

## ğŸ¯ What is Code Review Crew?

Code Review Crew is an **autonomous multi-agent system** where AI agents collaborate in real-time discussions to analyze code from multiple perspectives. Think of it as having a team of expert developers reviewing your code simultaneously.

**Core Technologies:**
- ğŸ¤– **Microsoft AutoGen** - Multi-agent orchestration and group chat
- ğŸ§  **OpenAI GPT-4** - Advanced code analysis capabilities
- ğŸ› ï¸ **Static Analysis Tools** - Pylint, Bandit, Radon integration
- ğŸ¨ **Streamlit** - Interactive web interface
- ğŸ³ **Docker** - Safe code execution (optional)

## ğŸ’¡ Why This Project?

This project demonstrates **production-ready multi-agent AI patterns**:

âœ… **Multi-Agent Collaboration** - Agents discuss and reach consensus through natural dialogue  
âœ… **Group Chat Orchestration** - Complex agent interaction patterns using AutoGen  
âœ… **Tool Integration Architecture** - Extensible design for static analysis tools  
âœ… **Comprehensive Analysis** - Security, performance, quality, and testing coverage  
âœ… **Real-World Application** - Solves actual code review challenges  

---

## ğŸ—ï¸ Multi-Agent Architecture

### Agent Team

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   User Submits Code â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Review Orchestrator â”‚
                    â”‚   (Coordinates Team) â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                      â”‚                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Code Analyzer  â”‚   â”‚ Security        â”‚   â”‚ Performance      â”‚
â”‚ â€¢ Style issues â”‚   â”‚ Reviewer        â”‚   â”‚ Optimizer        â”‚
â”‚ â€¢ Code smells  â”‚   â”‚ â€¢ Vulnerabilitiesâ”‚   â”‚ â€¢ Complexity     â”‚
â”‚ â€¢ Best practicesâ”‚   â”‚ â€¢ OWASP Top 10  â”‚   â”‚ â€¢ Bottlenecks    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### How It Works

1. **User submits code** via Streamlit UI or CLI
2. **Review Orchestrator** coordinates the review process
3. **Specialized agents** analyze from different perspectives:
   - **Code Analyzer**: Style, structure, maintainability
   - **Security Reviewer**: Vulnerabilities, exploits, security best practices
   - **Performance Optimizer**: Algorithm complexity, bottlenecks, optimizations
4. **Agents discuss** findings through AutoGen group chat
5. **Orchestrator synthesizes** final report with prioritized issues
6. **User receives** comprehensive review with grades and actionable fixes

---

## âœ¨ Key Features

### ğŸ¤– Multi-Agent Collaboration

Agents engage in natural conversations to analyze code:

```
[ReviewOrchestrator]: "Let's begin the review. CodeAnalyzer, please start."

[CodeAnalyzer]: "I found SQL injection on line 4, nested loops causing O(nÂ²) 
complexity, and MD5 hashing which is cryptographically weak."

[SecurityReviewer]: "Confirming SQL injection - this is CRITICAL. Also found 
hardcoded API key on line 24. These must be addressed immediately."

[PerformanceOptimizer]: "The nested loop is O(nÂ²). Suggesting hash map approach 
for O(n) complexity. Also recommend caching for repeated calls."

[ReviewOrchestrator]: "Final grade: C-. Priority: Fix SQL injection (Critical), 
then O(nÂ²) loops (High), then hardcoded secrets (Critical)."
```

### ğŸ›¡ï¸ Comprehensive Analysis

**Multi-Dimensional Review:**
- **Code Quality**: PEP 8 compliance, readability, maintainability
- **Security**: SQL injection, XSS, weak crypto, hardcoded secrets
- **Performance**: Time/space complexity, bottlenecks, optimizations
- **Best Practices**: Error handling, documentation, design patterns

**Tool Integration Ready:**
- Pylint for code quality metrics
- Bandit for security vulnerability scanning
- Radon for cyclomatic complexity analysis
- Extensible architecture for additional tools

### ğŸ“Š Structured Reports

```markdown
## Code Review Summary
Grade: C-

### ğŸ”´ Critical Issues (3)
1. SQL Injection in get_user function (Line 4)
2. Weak MD5 cryptography in hash_password (Line 21)
3. Hardcoded API key (Line 24)

### ğŸŸ¡ High Priority (1)
1. O(nÂ²) nested loops in process_data (Line 12-15)

### ğŸ’¡ Recommendations
- Use parameterized queries for SQL
- Replace MD5 with bcrypt
- Move secrets to environment variables
- Optimize nested loop with hash map
```

---

## ğŸ› ï¸ Installation & Setup

### Prerequisites

```bash
Python 3.9+
OpenAI API key
```

### Quick Start

1. **Clone the repository**
```bash
git clone https://github.com/bryan-lolordo/code-review-crew.git
cd code-review-crew
```

2. **Create virtual environment**
```bash
python -m venv .venv

# On Windows:
.venv\Scripts\activate

# On Mac/Linux:
source .venv/bin/activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Configure environment variables**
```bash
# Create .env file
echo "OPENAI_API_KEY=your_key_here" > .env
```

5. **Run the application**
```bash
streamlit run app.py
```

Navigate to `http://localhost:8501` in your browser.

---

## ğŸ’» Usage

### Web Interface

1. **Load Example Code**
   - Click "Load Example" radio button
   - Select from predefined examples (SQL Injection, Performance Issues, etc.)
   - Or paste your own Python code

2. **Configure Review** (Optional)
   - Adjust max conversation rounds (5-30)
   - Set AI temperature (0.0-1.0)
   - Choose analysis depth

3. **Start Review**
   - Click "ğŸš€ Start Review" button
   - Wait 30-60 seconds while agents analyze
   - Watch agents collaborate in real-time

4. **View Results**
   - **Results Tab**: See final grades and prioritized issues
   - **Agent Chat Tab**: Watch full conversation between agents
   - Each agent provides specific analysis and recommendations

### Command Line

```bash
# Test the standalone version
python run_group_chat_standalone.py

# Test with real tools integration
python run_group_chat.py
```

---

## ğŸ“ Project Structure

```
code-review-crew/
â”œâ”€â”€ README.md                        # This file
â”œâ”€â”€ ARCHITECTURE.md                  # Detailed technical documentation
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ .env                            # Environment variables (create this)
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ app.py                          # Streamlit web interface
â”œâ”€â”€ run_group_chat.py               # AutoGen integration with tools
â”œâ”€â”€ run_group_chat_standalone.py    # Standalone demo version
â”œâ”€â”€ autogen_integration.py          # Helper for agent integration
â”‚
â”œâ”€â”€ code_review_crew/               # Main package
â”‚   â”œâ”€â”€ agents/                     # Agent definitions
â”‚   â”‚   â”œâ”€â”€ base_agent.py          # Abstract base class
â”‚   â”‚   â”œâ”€â”€ orchestrator.py        # Review coordinator
â”‚   â”‚   â”œâ”€â”€ code_analyzer.py       # Code quality expert
â”‚   â”‚   â”œâ”€â”€ security_reviewer.py   # Security expert
â”‚   â”‚   â”œâ”€â”€ performance_optimizer.py # Performance expert
â”‚   â”‚   â”œâ”€â”€ test_generator.py      # Test creation expert
â”‚   â”‚   â””â”€â”€ code_executor.py       # Safe code execution
â”‚   â”‚
â”‚   â”œâ”€â”€ tools/                      # Analysis tools
â”‚   â”‚   â”œâ”€â”€ linting_tool.py        # Pylint wrapper
â”‚   â”‚   â”œâ”€â”€ security_scanner.py    # Bandit wrapper
â”‚   â”‚   â”œâ”€â”€ complexity_analyzer.py # Radon wrapper
â”‚   â”‚   â”œâ”€â”€ test_runner.py         # Pytest wrapper
â”‚   â”‚   â””â”€â”€ git_tool.py            # Git diff parser
â”‚   â”‚
â”‚   â””â”€â”€ utils/                      # Helper utilities
â”‚       â”œâ”€â”€ code_parser.py         # AST parsing
â”‚       â”œâ”€â”€ report_generator.py    # Report formatting
â”‚       â””â”€â”€ sandbox_manager.py     # Docker management
â”‚
â””â”€â”€ examples/                       # Example code files
    â”œâ”€â”€ sql_injection.py
    â”œâ”€â”€ performance_issues.py
    â””â”€â”€ security_issues.py
```

---

## ğŸ¯ AutoGen Patterns Demonstrated

### 1. **Group Chat Orchestration**
Multiple agents engage in structured conversations to analyze code collaboratively.

### 2. **Agent Specialization**
Each agent has a specific expertise and system prompt guiding their analysis.

### 3. **Consensus Building**
Agents discuss, debate, and agree on issue priorities through natural dialogue.

### 4. **Tool Integration Architecture**
Extensible design allows agents to call external analysis tools when needed.

### 5. **Iterative Refinement**
Agents can build on each other's findings for comprehensive analysis.

---

## ğŸ“Š Example Output

### Input Code:
```python
def get_user(username):
    query = f"SELECT * FROM users WHERE name = '{username}'"
    return db.execute(query)

def hash_password(password):
    import hashlib
    return hashlib.md5(password.encode()).hexdigest()

API_KEY = "sk-1234567890abcdef"
```

### Agent Analysis:

**CodeAnalyzer** identified:
- SQL injection vulnerability (Line 3)
- Import statement inside function (Line 6)
- Hardcoded secret (Line 9)

**SecurityReviewer** confirmed:
- CRITICAL: SQL injection - Use parameterized queries
- CRITICAL: Weak MD5 hashing - Use bcrypt instead
- CRITICAL: Hardcoded API key - Use environment variables

**ReviewOrchestrator** synthesized:
- Overall Grade: **C-**
- 3 Critical issues requiring immediate attention
- Provided specific code fixes for each issue

---

## ğŸ”‘ Core Dependencies

```
pyautogen==0.2.32          # Multi-agent orchestration
openai>=1.0.0              # LLM API
streamlit>=1.28.0          # Web interface
pylint>=3.0.0              # Code quality analysis
bandit>=1.7.5              # Security scanning
radon>=6.0.1               # Complexity analysis
python-dotenv>=1.0.0       # Environment management
```

---

## ğŸš€ What Makes This Special

### Advanced Multi-Agent Patterns

1. **Natural Language Collaboration**: Agents communicate through conversation, not just API calls
2. **Emergent Intelligence**: Insights arise from agent interactions
3. **Modular Architecture**: Easy to add new agents or modify existing ones
4. **Production-Ready Design**: Proper error handling, logging, and testing structure

### Real-World Application

- Solves actual code review challenges
- Provides actionable feedback with specific line numbers
- Grades code quality (A-F scale)
- Prioritizes issues by severity
- Demonstrates multi-agent systems at scale

---

## ğŸ“š Documentation

For detailed technical architecture and implementation details:
- [ARCHITECTURE.md](ARCHITECTURE.md) - Complete technical documentation
- [API Documentation](#) - Coming soon
- [Tutorial Videos](#) - Coming soon

---

## ğŸ™ Acknowledgments

**AI Frameworks:**
- [Microsoft AutoGen](https://github.com/microsoft/autogen) - Multi-agent orchestration
- [OpenAI API](https://openai.com/) - Language models

**Analysis Tools:**
- [Pylint](https://pylint.org/) - Python code analysis
- [Bandit](https://bandit.readthedocs.io/) - Security linting
- [Radon](https://radon.readthedocs.io/) - Code metrics

---

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) file for details

---

## ğŸ‘¤ Author

**Bryan LoLordo**
- GitHub: [@bryan-lolordo](https://github.com/bryan-lolordo)
- Focus: Multi-Agent AI Systems & Production ML
- Portfolio: Demonstrating advanced AutoGen patterns

---

## ğŸ“ Learning Outcomes

This project demonstrates proficiency in:

âœ… Multi-agent system architecture and design  
âœ… Microsoft AutoGen framework and group chat patterns  
âœ… LLM orchestration and prompt engineering  
âœ… Tool integration and API design  
âœ… Production-ready Python development  
âœ… Modular, testable, maintainable code architecture  

---

**Built with â¤ï¸ using Multi-Agent AI**

*Transforming code review through collaborative AI agents* ğŸš€