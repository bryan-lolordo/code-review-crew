# ğŸ” Code Review Crew - Multi-Agent Code Analysis System

**[ğŸ“º Demo Coming Soon](#)**

An intelligent multi-agent system powered by **Microsoft AutoGen** that performs comprehensive code reviews through collaborative AI agents. The system orchestrates specialized agents that debate, analyze, and provide actionable feedback on code quality, security, performance, and testing.

## ğŸ¯ What is Code Review Crew?

Code Review Crew is an **autonomous multi-agent system** that replaces traditional code review processes with AI-powered analysis. Multiple specialized agents collaborate in real-time discussions to provide comprehensive, expert-level code feedback.

**Key Technologies:**
- ğŸ¤– Microsoft AutoGen for multi-agent orchestration
- ğŸ§  OpenAI GPT-4 for code analysis
- ğŸ›¡ï¸ Static analysis tools (Pylint, Bandit, Radon)
- ğŸ¨ Streamlit for web interface
- ğŸ³ Docker for safe code execution

## ğŸ’¡ Why This Project?

This project demonstrates **advanced multi-agent AI patterns**:

âœ… **Multi-Agent Collaboration** - Agents debate and reach consensus  
âœ… **Code Execution** - Safe sandboxed code running and testing  
âœ… **Real Tool Integration** - Actual linting and security scanners  
âœ… **Group Chat Orchestration** - Complex agent interaction patterns  
âœ… **Production-Ready Architecture** - Modular, testable, documented  

---

## ğŸ—ï¸ Multi-Agent Architecture

### Agent Team

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   User Submits Code â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Review Orchestrator â”‚
                    â”‚   (Manages Flow)     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                      â”‚                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Code Analyzer  â”‚   â”‚ Security        â”‚   â”‚ Performance      â”‚
â”‚ - Code smells  â”‚   â”‚ Reviewer        â”‚   â”‚ Optimizer        â”‚
â”‚ - Bugs         â”‚   â”‚ - Vulnerabilitiesâ”‚   â”‚ - Complexity     â”‚
â”‚ - Style issues â”‚   â”‚ - Best practices â”‚   â”‚ - Bottlenecks    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                      â”‚                      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Test Generator     â”‚
                    â”‚  - Unit tests       â”‚
                    â”‚  - Edge cases       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Code Executor      â”‚
                    â”‚  - Runs tests       â”‚
                    â”‚  - Validates fixes  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Agent Roles

**Review Orchestrator**
- Manages the review workflow
- Synthesizes feedback from all agents
- Prioritizes issues by severity
- Generates final review report

**Code Analyzer**
- Identifies code smells and anti-patterns
- Checks code style and conventions
- Detects potential bugs
- Suggests refactoring opportunities

**Security Reviewer**
- Scans for security vulnerabilities
- Checks for common exploits (SQL injection, XSS, etc.)
- Reviews authentication and authorization
- Validates input sanitization

**Performance Optimizer**
- Analyzes algorithmic complexity
- Identifies performance bottlenecks
- Suggests optimization strategies
- Reviews memory usage patterns

**Test Generator**
- Creates comprehensive unit tests
- Generates edge case scenarios
- Provides test coverage analysis
- Suggests integration tests

**Code Executor**
- Safely runs code in Docker sandbox
- Executes generated tests
- Validates proposed fixes
- Reports runtime errors

---

## âœ¨ Key Features

### ğŸ¤– Multi-Agent Collaboration

**Group Chat Debates**
```python
# Agents engage in iterative discussions
Code Analyzer: "This function has O(nÂ²) complexity..."
Performance Optimizer: "Agreed. I suggest using a hash map..."
Security Reviewer: "But first, we need to sanitize the input..."
Orchestrator: "Let's prioritize security, then optimize..."
```

**Consensus Building**
- Agents can agree, disagree, or build on each other's findings
- Natural conversation flow mimics human code reviews
- Emergent insights from agent interactions

### ğŸ›¡ï¸ Comprehensive Analysis

**Multi-Dimensional Review**
- **Code Quality:** Style, readability, maintainability
- **Security:** Vulnerabilities, exploits, best practices
- **Performance:** Complexity, bottlenecks, optimization
- **Testing:** Coverage, edge cases, test quality
- **Documentation:** Comments, docstrings, clarity

**Real Tool Integration**
```python
# Actual static analysis tools
pylint_score = run_pylint(code)
security_issues = run_bandit(code)
complexity = calculate_complexity(code)
test_coverage = run_pytest_coverage(code)
```

### ğŸ³ Safe Code Execution

**Docker Sandbox**
- Isolated execution environment
- No access to host system
- Resource limits (CPU, memory, time)
- Automatic cleanup after execution

**Test Validation**
```python
# Generated tests are actually executed
test_results = executor.run_tests(generated_tests)
if test_results.passed:
    print("âœ… All tests pass!")
```

### ğŸ“Š Actionable Reports

**Structured Feedback**
```markdown
## Code Review Summary

### ğŸ”´ Critical Issues (2)
1. SQL Injection vulnerability in line 45
2. Unhandled exception in line 78

### ğŸŸ¡ Warnings (5)
1. Function complexity too high (12/10)
2. Missing input validation
...

### ğŸ’¡ Suggestions (8)
1. Consider using list comprehension
2. Extract method for better readability
...

### âœ… Strengths
- Well-documented functions
- Good error handling in most cases
```

---

## ğŸ› ï¸ Installation & Setup

### Prerequisites
```bash
Python 3.9+
OpenAI API key
Docker (for code execution)
```

### Quick Start

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/code-review-crew.git
cd code-review-crew
```

2. **Create virtual environment**
```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Configure environment variables**
```bash
cp .env.example .env
# Edit .env with your API key:
# OPENAI_API_KEY=your_key_here
```

5. **Run the application**
```bash
streamlit run app.py
```

Navigate to `http://localhost:8501`

---

## ğŸ’» Usage

### Web Interface (Recommended)

1. **Paste or Upload Code**
   - Copy-paste code directly
   - Upload Python files
   - Load from examples

2. **Configure Review**
   - Select analysis depth (quick/standard/deep)
   - Choose which agents to include
   - Enable/disable code execution

3. **Start Review**
   - Watch agents collaborate in real-time
   - See the group chat conversation
   - Get final consolidated report

4. **Apply Fixes**
   - Review suggested changes
   - See before/after comparisons
   - Download improved code

### CLI Interface

```bash
# Review a single file
python -m code_review_crew.cli review mycode.py

# Review with specific agents
python -m code_review_crew.cli review mycode.py --agents security performance

# Generate tests only
python -m code_review_crew.cli generate-tests mycode.py

# Batch review multiple files
python -m code_review_crew.cli review-batch src/
```

---

## ğŸ“ Project Structure

```
code-review-crew/
â”œâ”€â”€ README.md
â”œâ”€â”€ ARCHITECTURE.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ code_review_crew/                # Main package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agents/                      # Agent definitions
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ code_analyzer.py
â”‚   â”‚   â”œâ”€â”€ security_reviewer.py
â”‚   â”‚   â”œâ”€â”€ performance_optimizer.py
â”‚   â”‚   â”œâ”€â”€ test_generator.py
â”‚   â”‚   â”œâ”€â”€ code_executor.py
â”‚   â”‚   â””â”€â”€ orchestrator.py
â”‚   â”‚
â”‚   â”œâ”€â”€ tools/                       # Analysis tools
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ linting_tool.py         # Pylint integration
â”‚   â”‚   â”œâ”€â”€ security_scanner.py     # Bandit integration
â”‚   â”‚   â”œâ”€â”€ complexity_analyzer.py  # Radon integration
â”‚   â”‚   â””â”€â”€ test_runner.py          # Pytest integration
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                       # Helper utilities
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ code_parser.py
â”‚   â”‚   â”œâ”€â”€ report_generator.py
â”‚   â”‚   â””â”€â”€ sandbox_manager.py
â”‚   â”‚
â”‚   â””â”€â”€ config.py                    # Configuration
â”‚
â”œâ”€â”€ app.py                           # Streamlit web interface
â”‚
â”œâ”€â”€ examples/                        # Example code for testing
â”‚   â”œâ”€â”€ simple_function.py
â”‚   â”œâ”€â”€ security_issues.py
â”‚   â”œâ”€â”€ performance_issues.py
â”‚   â””â”€â”€ complex_class.py
â”‚
â””â”€â”€ tests/                           # Unit tests
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_agents.py
    â”œâ”€â”€ test_tools.py
    â””â”€â”€ test_integration.py
```

---

## ğŸ¯ AutoGen Patterns Demonstrated

### 1. **Group Chat Orchestration**
Multiple agents engage in free-form conversation to solve complex problems.

### 2. **Code Execution Agents**
Safe execution of untrusted code with UserProxyAgent and Docker.

### 3. **Tool-Augmented Agents**
Agents enhanced with real static analysis tools for concrete results.

### 4. **Iterative Refinement**
Agents can critique each other's suggestions and iterate to better solutions.

### 5. **Human-in-the-Loop**
Optional human intervention at key decision points.

### 6. **Consensus Building**
Agents negotiate and agree on prioritization of issues.

---

## ğŸ”¬ Advanced Features

### Real-Time Agent Visualization

Watch agents collaborate:
```
[Code Analyzer] ğŸ” Analyzing code structure...
[Security Reviewer] ğŸ›¡ï¸ Found potential SQL injection on line 45
[Performance Optimizer] âš¡ This loop is O(nÂ²), suggesting optimization...
[Code Analyzer] ğŸ’¬ Agreed with security concern, should be top priority
[Orchestrator] ğŸ“‹ Prioritizing issues: Security (Critical) > Performance (High)
```

### Custom Agent Configuration

```python
# Create custom agent teams
quick_review = [code_analyzer, orchestrator]
security_focused = [security_reviewer, code_analyzer, orchestrator]
full_review = [code_analyzer, security_reviewer, 
               performance_optimizer, test_generator, orchestrator]
```

### Learning from Feedback

```python
# Agents improve based on user feedback
if user_accepted_suggestion:
    agent.learn_from_success(suggestion)
else:
    agent.learn_from_failure(suggestion, user_feedback)
```

---

## ğŸ“Š Example Review Output

```markdown
# Code Review: user_authentication.py

## Summary
Reviewed 150 lines of Python code
Review time: 2m 34s
Overall Grade: C+ (Needs Improvement)

## Critical Issues ğŸ”´

### 1. SQL Injection Vulnerability (Line 45)
**Severity:** Critical  
**Agent:** Security Reviewer  
**Description:** User input directly concatenated into SQL query

```python
# âŒ Current (Vulnerable)
query = f"SELECT * FROM users WHERE username = '{username}'"

# âœ… Suggested Fix
query = "SELECT * FROM users WHERE username = ?"
cursor.execute(query, (username,))
```

**Impact:** Attackers could execute arbitrary SQL commands
**Fix Effort:** Low (5 minutes)

### 2. Unhandled Exception (Line 78)
**Severity:** High  
**Agent:** Code Analyzer  
...

## Performance Issues ğŸŸ¡

### 1. Inefficient Algorithm (Line 112)
**Current Complexity:** O(nÂ²)  
**Suggested Complexity:** O(n)  
...

## Generated Tests âœ…

```python
def test_valid_login():
    assert authenticate("user", "pass123") == True

def test_sql_injection_attempt():
    malicious = "' OR '1'='1"
    assert authenticate(malicious, "any") == False
    
def test_empty_credentials():
    assert authenticate("", "") == False
```

## Recommendations

1. **Immediate:** Fix SQL injection (Critical)
2. **Short-term:** Add input validation
3. **Long-term:** Implement rate limiting
```

---

## ğŸ” Security Considerations

1. **Code Execution Safety**: All code runs in isolated Docker containers
2. **API Key Management**: Environment variables, never committed
3. **Input Sanitization**: All user code sanitized before analysis
4. **Resource Limits**: CPU, memory, and time limits on execution
5. **Audit Logging**: All reviews logged for security auditing

---

## ğŸš§ Roadmap

**Planned Features:**
- Support for multiple languages (JavaScript, Java, Go)
- GitHub PR integration for automated reviews
- VS Code extension
- Custom rule configuration
- Team collaboration features
- Historical review analytics
- AI-powered fix generation

---

## ğŸ“š Documentation

For detailed technical architecture, see [ARCHITECTURE.md](ARCHITECTURE.md)

Topics covered:
- Multi-agent system design
- AutoGen group chat patterns
- Tool integration architecture
- Code execution sandboxing
- Agent communication protocols

---

## ğŸ™ Acknowledgments

**AI Frameworks**
- [Microsoft AutoGen](https://github.com/microsoft/autogen) - Multi-agent orchestration
- [OpenAI API](https://openai.com/) - Language models

**Analysis Tools**
- [Pylint](https://pylint.org/) - Code linting
- [Bandit](https://bandit.readthedocs.io/) - Security scanning
- [Radon](https://radon.readthedocs.io/) - Complexity analysis
- [Pytest](https://pytest.org/) - Testing framework

---

## ğŸ“„ License

MIT License

---

## ğŸ‘¤ Author

**Bryan LoLordo**
- Specialization: Multi-Agent AI Systems, Code Analysis
- Focus: Production-ready AI agents with Microsoft AutoGen

---

**Built with â¤ï¸ using Multi-Agent AI patterns**

*Demonstrating advanced agent collaboration for code review automation* ğŸ¯